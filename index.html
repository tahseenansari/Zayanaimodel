
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>NeuraX Voice Interface</title>
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Orbitron&display=swap');

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
      font-family: 'Orbitron', sans-serif;
    }

    body {
      background: radial-gradient(circle at top, #0c0f1a 0%, #000 100%);
      color: #00fff2;
      display: flex;
      flex-direction: column;
      height: 100vh;
      justify-content: space-between;
      overflow: hidden;
    }

    header {
      text-align: center;
      font-size: 26px;
      padding: 20px;
      text-shadow: 0 0 10px #00fff2;
    }

    .chat-box {
      flex: 1;
      display: flex;
      justify-content: center;
      align-items: center;
      padding: 20px;
    }

    .avatars {
      display: flex;
      gap: 80px;
      align-items: center;
    }

    .avatar {
      width: 140px;
      height: 140px;
      border-radius: 50%;
      background-size: cover;
      background-position: center;
      box-shadow: 0 0 20px #00fff2, 0 0 40px #00fff280;
      border: 2px solid #00fff2;
      cursor: pointer; /* Indicate it's clickable */
      transition: transform 0.2s ease-in-out;
    }

    .avatar:hover {
      transform: scale(1.1); /* Subtle hover effect */
    }

    .user-avatar {
      background-image: url('https://cdn.dribbble.com/userupload/21344132/file/original-84d4cc5c43376fdf389c9954e2499954.gif'); /* Replace with user image */
    }

    .status {
      text-align: center;
      font-size: 16px;
      padding: 10px;
      color: #00fff2a8;
    }

    .loading {
      animation: pulse 1.5s infinite alternate;
    }

    @keyframes pulse {
      0% {
        opacity: 0.7;
      }
      100% {
        opacity: 1;
      }
    }

    footer {
      text-align: center;
      padding: 10px;
      font-size: 12px;
      color: #00fff2a8;
    }

  </style>
</head>
<body>

  <header>Gura AI</header>

  <div class="chat-box">
    <div class="avatars">
      <div class="avatar user-avatar" id="userAvatar"></div>
    </div>
  </div>

  <div class="status" id="status">Click on the avatar to start speaking</div>

  <script>
    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    const recognition = new SpeechRecognition();
    recognition.continuous = false; // Listen only once per click
    recognition.interimResults = false;
    recognition.lang = 'en-US';
    recognition.maxAlternatives = 1;

    const status = document.getElementById("status");
    const userAvatar = document.getElementById("userAvatar");

    // **VectorShift API Configuration**
    const vectorShiftApiKey = "sk_ceVR7K2RqnlXqqxALevhSLrBH1juX2OSasS4lVb7nlJ7Xdh0"; // **REPLACE WITH YOUR ACTUAL API KEY**
    const vectorShiftChatbotName = "unites"; // Replace with your chatbot name in VectorShift
    const vectorShiftUsername = "dfh_67"; // You can set a default username
    let vectorShiftConversationId = null;

    let isSpeaking = false;
    let isRecognizing = false;

    async function speak(text) {
      isSpeaking = true;
      status.textContent = "NeuraX is speaking...";
      await stopRecognition(); // Ensure recognition is stopped
      userAvatar.classList.remove("loading");

      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'en-US';
      utterance.pitch = 1.7;
      utterance.rate = 1;
      utterance.volume = 1;

      utterance.onstart = () => {
        userAvatar.classList.add("speaking"); //Optional speaking animation
      }

      utterance.onend = () => {
        isSpeaking = false;
        status.textContent = "Click on the avatar to start speaking";
        userAvatar.classList.remove("speaking"); //Remove speaking animation
      };

      utterance.onerror = (event) => {
        console.error("Speech synthesis error:", event);
        isSpeaking = false;
        status.textContent = "Error: Failed to speak the response.";
        userAvatar.classList.remove("speaking"); //Remove speaking animation
      };

      speechSynthesis.speak(utterance);
    }

    function startRecognition() {
      return new Promise((resolve, reject) => { // Return a Promise
        if (!isRecognizing) {
          try {
            recognition.start();
            isRecognizing = true;
            status.textContent = "Listening...";
            userAvatar.classList.add("listening");
            console.log("Recognition started.");
            resolve(); // Resolve the promise after starting
          } catch (error) {
            console.error("Error starting recognition:", error);
            status.textContent = `Error: ${error}`;
            isRecognizing = false;
            userAvatar.classList.remove("listening");
            reject(error); // Reject the promise if there's an error
          }
        } else {
          console.log("Recognition already started.");
          resolve(); // Resolve if already started
        }
      });
    }

    function stopRecognition() {
      return new Promise(resolve => {
        if (isRecognizing) {
          console.log("Stopping recognition...");
          recognition.stop();
          isRecognizing = false;
          userAvatar.classList.remove("listening");
          console.log("Recognition stopped. isRecognizing set to false.");
          recognition.onend = () => {
            console.log("Recognition stopped from onend handler.");
            resolve();
          }

        } else {
          console.log("stopRecognition() called, but recognition was not running.");
          resolve();
        }
      });
    }

    recognition.onresult = async (event) => {
      let finalTranscript = event.results[0][0].transcript;
      status.textContent = `You said: "${finalTranscript}"`;
      await stopRecognition();
      userAvatar.classList.remove("listening");

      try {
        status.textContent = "Thinking...";
        userAvatar.classList.add("loading"); // Add a loading animation
        const aiResponse = await getVectorShiftResponse(finalTranscript);
        await speak(aiResponse);
      } catch (error) {
        console.error("Error with VectorShift API:", error);
        status.textContent = `Error: ${error}`;
        await speak("An error occurred while processing your request.");
      }
    };

    recognition.onerror = (event) => {
      console.error("Speech recognition error:", event.error);
      status.textContent = `Error: ${event.error}`;
      isRecognizing = false;
      userAvatar.classList.remove("listening");
    };

    recognition.onend = () => {
      console.log("Recognition ended.");
      isRecognizing = false;
      userAvatar.classList.remove("listening");
      status.textContent = "Click on the avatar to start speaking"; // Reset status
    };

    userAvatar.addEventListener("click", async () => {
      if (!isSpeaking) {
        try {
          await startRecognition();
          console.log("Recognition started after image click");
        } catch (error) {
          console.error("Error starting recognition after image click:", error);
          status.textContent = `Error: ${error}`;
        }
      } else {
        status.textContent = "Please wait until NeuraX finishes speaking.";
      }
    });

    // **VectorShift API Interaction Function**
    async function getVectorShiftResponse(prompt) {
      try {
        const bodyData = {
          input: prompt,
          chatbot_name: vectorShiftChatbotName,
          username: vectorShiftUsername,
          conversation_id: vectorShiftConversationId, // Include conversation ID
        };

        const response = await fetch("https://api.vectorshift.ai/api/chatbots/run", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Api-Key": vectorShiftApiKey,
          },
          body: JSON.stringify(bodyData),
        });

        if (!response.ok) {
          const errorData = await response.json();
          throw new Error(`VectorShift API Error: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
        }

        const data = await response.json();

        // Update conversation ID if it's the first interaction or if the API returns a new one
        if (!vectorShiftConversationId && data.conversation_id) {
          vectorShiftConversationId = data.conversation_id;
        }
        if (data.conversation_id && data.conversation_id !== vectorShiftConversationId){
            vectorShiftConversationId = data.conversation_id;
        }
        if (data.output) {
          return data.output;
        } else {
          throw new Error("No output received from VectorShift API.");
        }
      } catch (error) {
        console.error("Error getting VectorShift response:", error);
        throw error; // Re-throw the error so it can be handled in the recognition.onresult function
      }
    }
  </script>

</body>
  </html>
